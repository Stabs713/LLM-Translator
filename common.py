import os
import requests
from tqdm import tqdm
from dotenv import load_dotenv
import re

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
INPUT_DIR = "inputs"
OUTPUT_DIR = "outputs"

# –ó–∞—â–∏—â—ë–Ω–Ω—ã–µ –º–∞–∫—Ä–æ—Å—ã ‚Äî –ù–ï –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å
PROTECTED_MACROS = {
    'cite', 'ref', 'label', 'eqref', 'footnote', 'url', 'href', 'includegraphics',
    'input', 'include', 'usepackage', 'documentclass', 'bibitem', 'index',
    'begin', 'end', 'hline', 'cline', 'multicolumn', 'multirow'
}

# –ú–∞–∫—Ä–æ—Å—ã, —á—å–∏ –∞—Ä–≥—É–º–µ–Ω—Ç—ã –ú–û–ñ–ù–û –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—å
TRANSLATABLE_MACROS = {
    'section', 'subsection', 'subsubsection', 'chapter', 'part',
    'caption', 'title', 'author', 'date', 'abstract',
    'textbf', 'textit', 'emph', 'underline', 'item', 'texttt'
}

# –ó–∞—â–∏—â—ë–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–ù–ï –ø–µ—Ä–µ–≤–æ–¥–∏–º)
PROTECTED_ENVIRONMENTS = {
    'equation', 'align', 'gather', 'multline', 'eqnarray',
    'verbatim', 'lstlisting', 'code', 'minted', 'displaymath', 'math',
    'figure'
}

# –¢—Ä–∞–Ω—Å–ª–∏—Ä—É–µ–º—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è (–ø–µ—Ä–µ–≤–æ–¥–∏–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ)
TRANSLATABLE_ENVIRONMENTS = {
    'tabular',
    'table',
    'itemize',
    'enumerate'
}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
PROXY_API_URL = None
PROXY_API_KEY = None
CURRENT_MODEL = "gpt-4o"

def load_env_vars():
    global PROXY_API_URL, PROXY_API_KEY
    load_dotenv()
    PROXY_API_URL = os.getenv("PROXY_API_URL", "https://api.proxyapi.ru/openai/v1/chat/completions")
    PROXY_API_KEY = os.getenv("PROXY_API_KEY")
    if not PROXY_API_KEY:
        raise ValueError("‚ùå PROXY_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ .env. –î–æ–±–∞–≤—å—Ç–µ –µ–≥–æ.")

def set_current_model(model_name):
    global CURRENT_MODEL
    CURRENT_MODEL = model_name

def get_current_model():
    return CURRENT_MODEL

def chunk_text_by_sentences_safe(text, max_tokens=1200):
    """
    –†–∞–∑–±–∏–≤–∞–µ—Ç —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞–Ω–∫–∏, –Ω–æ –ù–ò–ö–û–ì–î–ê –Ω–µ –æ–±—Ä—ã–≤–∞–µ—Ç –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ.
    –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è –≤ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ ‚Äî –æ–Ω–æ –∏–¥—ë—Ç –≤ —Å–ª–µ–¥—É—é—â–∏–π.
    """
    if not text.strip():
        return [text]

    # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (—Å —É—á—ë—Ç–æ–º . ! ? –∏ –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–æ–∫—Ä–∞—â–µ–Ω–∏–π)
    sentences = re.split(r'(?<=[.!?])\s+(?=[–ê-–ØA-Z])', text.strip())
    if not sentences:
        return [text]

    chunks = []
    current_chunk = []
    current_len = 0

    for sent in sentences:
        tokens = len(sent) // 4  # –≥—Ä—É–±–∞—è –æ—Ü–µ–Ω–∫–∞

        # –ï—Å–ª–∏ —Ç–µ–∫—É—â–∏–π —á–∞–Ω–∫ –ø—É—Å—Ç ‚Äî –±–µ—Ä—ë–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –¥–∞–∂–µ –µ—Å–ª–∏ –æ–Ω–æ –¥–ª–∏–Ω–Ω–æ–µ
        if not current_chunk:
            current_chunk = [sent]
            current_len = tokens
        # –ï—Å–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø–æ–º–µ—â–∞–µ—Ç—Å—è ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º
        elif current_len + tokens <= max_tokens:
            current_chunk.append(sent)
            current_len += tokens
        # –ï—Å–ª–∏ –ù–ï –ø–æ–º–µ—â–∞–µ—Ç—Å—è ‚Äî –∑–∞–∫—Ä—ã–≤–∞–µ–º —á–∞–Ω–∫ –ë–ï–ó —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
        else:
            chunks.append(" ".join(current_chunk))
            current_chunk = [sent]  # –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π —á–∞–Ω–∫ —Å —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è
            current_len = tokens

    # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —á–∞–Ω–∫
    if current_chunk:
        chunks.append(" ".join(current_chunk))

    return chunks

def translate_chunk(text, retries=3):
    prompt = f"""–ü–µ—Ä–µ–≤–µ–¥–∏ –¢–û–õ–¨–ö–û —Ç–µ–∫—Å—Ç —Å –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π. –°–æ—Ö—Ä–∞–Ω–∏:
- –≤—Å–µ —Ñ–æ—Ä–º—É–ª—ã, –∫–æ–º–∞–Ω–¥—ã LaTeX (\\section, \\texttt, \\url, \\begin{{...}}, –∏ —Ç.–¥.) –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π,
- –∏—Å—Ö–æ–¥–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –∏ –ø—É–Ω–∫—Ç—É–∞—Ü–∏—é.
–ù–ï –î–û–ë–ê–í–õ–Ø–ô –Ω–∏—á–µ–≥–æ –æ—Ç —Å–µ–±—è: –Ω–∏–∫–∞–∫–∏—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤, –ø–æ—è—Å–Ω–µ–Ω–∏–π –∏–ª–∏ —Ñ—Ä–∞–∑ –≤—Ä–æ–¥–µ "–í—ã –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª–∏ —Ç–µ–∫—Å—Ç".

–¢–µ–∫—Å—Ç:
{text}"""

    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {PROXY_API_KEY}"
    }
    
    payload = {
        "model": get_current_model(),
        "messages": [{"role": "user", "content": prompt}],
        "max_tokens": 2000,
        "temperature": 0.1,
        "top_p": 0.9
    }

    for attempt in range(retries):
        try:
            response = requests.post(PROXY_API_URL, json=payload, headers=headers, timeout=120)
            if response.status_code == 200:
                result = response.json().get("choices", [{}])[0].get("message", {}).get("content", "").strip()
                if result:
                    return result
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ (–ø–æ–ø—ã—Ç–∫–∞ {attempt+1}/{retries}): {e}")
            pass
        if attempt < retries - 1:
            import time
            time.sleep(1)
    return text

def test_model_connection(model_name):
    print(f"üåê –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –º–æ–¥–µ–ª–∏: {model_name}")
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {PROXY_API_KEY}"
    }
    payload = {
        "model": model_name,
        "messages": [{"role": "user", "content": "ping"}],
        "max_tokens": 5
    }
    try:
        response = requests.post(PROXY_API_URL, json=payload, headers=headers, timeout=10)
        if response.status_code == 200:
            print(f"‚úÖ –ü–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –∫ –º–æ–¥–µ–ª–∏ {model_name} —É—Å–ø–µ—à–Ω–æ!")
            return True
        else:
            print(f"‚ùå –û—à–∏–±–∫–∞ HTTP {response.status_code}: {response.text}")
            return False
    except Exception as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è: {e}")
        return False

def get_files_list(directory):
    files = [f for f in os.listdir(directory) if f.lower().endswith(('.docx', '.tex', '.zip'))]
    return sorted(files)

def get_tex_files_list(directory):
    files = [f for f in os.listdir(directory) if f.lower().endswith('.tex')]
    return sorted(files)

def select_file_by_number(total_count):
    while True:
        try:
            choice = int(input(f"\n–í—ã–±–µ—Ä–∏—Ç–µ –Ω–æ–º–µ—Ä —Ñ–∞–π–ª–∞ (1-{total_count}): ").strip())
            if 1 <= choice <= total_count:
                return choice
            else:
                print(f"‚ùå –ù–æ–º–µ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ {total_count}.")
        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ.")

def select_main_action():
    print("\n–ß—Ç–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å?")
    print("1. –ü–µ—Ä–µ–≤–µ—Å—Ç–∏ —Ñ–∞–π–ª (.docx, .tex, .zip)")
    print("2. –°–∫–æ–º–ø–∏–ª–∏—Ä–æ–≤–∞—Ç—å .tex –≤ PDF")
    while True:
        try:
            choice = int(input("–í—ã–±–µ—Ä–∏—Ç–µ –¥–µ–π—Å—Ç–≤–∏–µ (1 –∏–ª–∏ 2): ").strip())
            if choice == 1:
                return "translate"
            elif choice == 2:
                return "compile"
            else:
                print("‚ùå –í–≤–µ–¥–∏—Ç–µ 1 –∏–ª–∏ 2.")
        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ.")

def select_translation_model():
    model_names = ["gpt-4o", "gpt-4.1"]
    print("\n–î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–µ—Ä–µ–≤–æ–¥–∞:")
    for i, name in enumerate(model_names, 1):
        print(f"  {i}. {name}")
    while True:
        try:
            choice = int(input(f"\n–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥–µ–ª—å (1-{len(model_names)}): ").strip())
            if 1 <= choice <= len(model_names):
                selected = model_names[choice - 1]
                print(f"‚úÖ –í—ã–±—Ä–∞–Ω–∞ –º–æ–¥–µ–ª—å: {selected}")
                return selected
            else:
                print(f"‚ùå –ù–æ–º–µ—Ä –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –æ—Ç 1 –¥–æ {len(model_names)}.")
        except ValueError:
            print("‚ùå –í–≤–µ–¥–∏—Ç–µ —á–∏—Å–ª–æ.")